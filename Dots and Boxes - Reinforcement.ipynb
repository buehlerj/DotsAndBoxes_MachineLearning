{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4a1331e4-b774-40b6-bb49-c16ea9589417"
    }
   },
   "source": [
    "# Dots and Boxes\n",
    "\n",
    "*Jeffrey Buehler & Bobby Signor*\n",
    "$\\newcommand{\\xv}{\\mathbf{x}}\n",
    "\\newcommand{\\Xv}{\\mathbf{X}}\n",
    "\\newcommand{\\yv}{\\mathbf{y}}\n",
    "\\newcommand{\\zv}{\\mathbf{z}}\n",
    "\\newcommand{\\av}{\\mathbf{a}}\n",
    "\\newcommand{\\Wv}{\\mathbf{W}}\n",
    "\\newcommand{\\wv}{\\mathbf{w}}\n",
    "\\newcommand{\\tv}{\\mathbf{t}}\n",
    "\\newcommand{\\Tv}{\\mathbf{T}}\n",
    "\\newcommand{\\muv}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\sigmav}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\phiv}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\Phiv}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\Sigmav}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\Lambdav}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\half}{\\frac{1}{2}}\n",
    "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\newcommand{\\argmin}[1]{\\underset{#1}{\\operatorname{argmin}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Our goal for this project was to create an AI capable of beating a random opponent at a game called Dots and Boxes at least 80% of the time, using reinforcement learning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "9f03bccb-0272-46b0-becd-425ea029f3f7"
    }
   },
   "source": [
    "### The Game\n",
    "\n",
    "Dots and Boxes is a simple game for two players. The gameboard consists of a grid of an abitrary size. For this project, we chose to fix the size of the board to 5 x 5 boxes.\n",
    "<figure>\n",
    "    <img src=\"img/0-empty.png\">\n",
    "    <figcaption>\n",
    "        <div style=\"text-align: center\">**Fig. 1.1:** An empty 5 x 5 board.</div>\n",
    "    </figcaption>\n",
    "</figure>\n",
    "\n",
    "Each player switches off taking turns. A turn starts with the player drawing a line between two adjacent unconnected dots. If the new line the player draws does not complete a 1 x 1 square, then that player's turn is over and it is the other player's turn.\n",
    "<figure>\n",
    "    <img src=\"img/fig2.png\">\n",
    "    <figcaption>\n",
    "        <div style=\"text-align: center\">**Fig. 1.2:** An example of a player taking a turn and not completing a box.</div>\n",
    "    </figcaption>\n",
    "</figure>\n",
    "\n",
    "However, if the player draws a line that does complete a 1 x 1 square, the player is rewarded a point for that box and gets to draw another line, with the above rule still in place.\n",
    "<figure>\n",
    "    <img src=\"img/fig3.png\">\n",
    "    <figcaption>\n",
    "        <div style=\"text-align: center\">**Fig. 1.3:** An example of a player drawing a line, completing a box, and then drawing another line.</div>\n",
    "    </figcaption>\n",
    "</figure>\n",
    "\n",
    "The game ends when it is no longer possible to draw another line. The winner is determined by whoever has the most boxes at the end of the game. In the example game shown in Figure 1.4, player X would be the winner.\n",
    "<figure>\n",
    "    <img src=\"img/fig4.png\">\n",
    "    <figcaption>\n",
    "        <div style=\"text-align: center\">**Fig. 1.4:** An example of a board after a game's been completed. Here, player X has 16 points, while player O has 9.</div>\n",
    "    </figcaption>\n",
    "</figure>\n",
    "\n",
    "#### A Simple Strategy\n",
    "\n",
    "While the objective of the game is to score more points than your opponent, it is not always wise to complete boxes as quickly as possible. One strategy that is quickly learned by human opponents is creating paths that can eventually be completed without giving your opponent a chance to counter, as shown in Figure 1.3. When used correctly, this strategy maximizes the number of points earned by reducing the number of opportunities your opponent has to draw lines. However, this must be done with care, since your opponent may also take the opportunity to complete your path and steal those points from you.\n",
    "<figure>\n",
    "    <img src=\"img/fig5.png\">\n",
    "    <figcaption>\n",
    "        <div style=\"text-align: center\">**Fig. 1.5:** An example of a board setup that would net a single player 9 points before the other player can take their turn.</div>\n",
    "    </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "7e41a529-91eb-4813-a621-90eccef0e207"
    }
   },
   "source": [
    "## Implementation\n",
    "\n",
    "### Game\n",
    "\n",
    "The Game object contains the complete state of the game and the logic required to correctly play it. Initializing it and starting a new game is as follows:\n",
    "\n",
    "```python\n",
    "g = Game()\n",
    "g.play(player1, player2)\n",
    "``` \n",
    "\n",
    "### Players\n",
    "\n",
    "We have created 2 different kinds of players for our game:\n",
    "\n",
    "1. **Random Player:** This player chooses moves simply by randomly choosing any of the available moves at random each time it's asked. Its play does not improve as it plays more games.\n",
    " \n",
    "2. **AI Player:** This player uses reinforcement learning techniques (see below) to learn which move given a board state is most likely to result in a win, and choosing that one. We can also have it make some of its moves randomly for training by specifying the probability it takes a random move in a parameter called epsilon. While training, we start epsilon at 1 and steadily decay that number as the AI Player is exposed to more board states and more games."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "bbbef074-015e-4ebb-9cdf-7a39c8883c7e"
    }
   },
   "source": [
    "## The Machine Learning Method: Reinforcement Programming\n",
    "\n",
    "### Reinforcement Learning\n",
    "\n",
    "Reinforcement learning is a method of machine learning used to teach a program to give correct output given input using reward/punishment. The behavior of a reinforced program is based on the psychological response of humans trying to suceed at a task. One way to picture this is to imagine a child being taught how to read by a grade-school teacher. They are presented with simple words and are asked to sound out the word. If presented incorrectly, the teacher will inform the child they were wrong and give feedback on how to improve. If the child pronounces the word correctly, they are given positive feedback, and sometimes some sort of reward. Eventually, the child will learn that certain letters interact with others in certian ways because they were given positive reinforcement when they did something correct.\n",
    "\n",
    "### Applied to AI Player\n",
    "\n",
    "We will be applying reinforcement learning to our AI Player. It will be reinforced depending on the moves it makes that end up winning a game. Positive reinforcement will be given whenever the AI is able to win a game. The decisions the AI makes will be determined on past experience of winning moves.\n",
    "\n",
    "### Hypothesis\n",
    "\n",
    "We believe if we train the AI enough, it will be able to defeat a random opponent easily. If we train it against another AI, it will be able to learn more sensible moves to make. We also believe that if trained against a human opponent, it will eventually learn the strategies talked about earlier that humans are able to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f0313035-aad9-4326-acb0-e24b675c1450"
    }
   },
   "source": [
    "## Required Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "8e058acd-0039-4fe8-98f4-1861e851a656"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# External Game & Player Code\n",
    "import game\n",
    "import players\n",
    "\n",
    "# Graphing\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import IPython.display as ipd\n",
    "\n",
    "# Misc.\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4a87510e-747b-4021-b1de-7fb71a7a20d8"
    }
   },
   "source": [
    "## Training/Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "cb2e6da6-921f-4799-800f-ace3643fc808"
    }
   },
   "outputs": [],
   "source": [
    "def playTestvsRandom(p1, p2, printturns = False):\n",
    "    start = time.time()\n",
    "    aiWins = 0\n",
    "    winPercent = {}\n",
    "    for i in range(trainIterations):\n",
    "        g = game.Game()\n",
    "        if i % 2 is 0:\n",
    "            g.play(p1, p2, printturns=printturns)\n",
    "        else:\n",
    "            g.play(p2, p1, printturns=printturns)\n",
    "        if g.score.index(max(g.score)) is p1.playernum:\n",
    "            aiWins += 1\n",
    "        winPercent[i] = aiWins / (i + 1)\n",
    "    print(\"Train vs. Random:\\t{} wins out of {}\".format(aiWins, trainIterations))\n",
    "    print(\"Took \", time.time() - start, \"seconds.\\n\")\n",
    "    return winPercent\n",
    "\n",
    "def playTrainvsRandom(p1, p2, printturns = False):\n",
    "    start = time.time()\n",
    "    aiWins = 0\n",
    "    winPercent = {}\n",
    "    p1.train = False\n",
    "    for i in range(randTestIterations):\n",
    "        g = game.Game()\n",
    "        if i % 2 is 0:\n",
    "            g.play(p1, p2, printturns=printturns)\n",
    "        else:\n",
    "            g.play(p2, p1, printturns=printturns)\n",
    "        if g.score.index(max(g.score)) is p1.playernum:\n",
    "            aiWins += 1\n",
    "        winPercent[i] = aiWins / (i + 1)\n",
    "    print(\"Test vs. Random:\\t{} wins out of {}\".format(aiWins, randTestIterations))\n",
    "    print(\"Took \", time.time() - start, \"seconds.\\n\")\n",
    "    return winPercent\n",
    "\n",
    "def playTrainvsSelf(p1, p2, printturns = False):\n",
    "    start = time.time()\n",
    "    wins = [0, 0]\n",
    "    p1.train = True\n",
    "    p1.epsilon = initialEpsilon\n",
    "    p2 = players.AIPlayer(rho=rho, epsilon=initialEpsilon, seed=seed2)\n",
    "    p2.Q = p1.Q\n",
    "    winPercent = {}\n",
    "    aiWins = 0\n",
    "    for i in range(aiTrainIterations):\n",
    "        g = game.Game()\n",
    "        g.play(p1, p2, printturns=False)\n",
    "        wins[g.score.index(max(g.score))] += 1\n",
    "        p1.epsilon *= epsilonDecay\n",
    "        p2.epsilon *= epsilonDecay\n",
    "        aiWins += 1\n",
    "        winPercent[i] = aiWins / (i + 1)\n",
    "    print(\"Train vs. Self:\\t{} wins to {} wins\".format(wins[0], wins[1]))\n",
    "    print(\"Took \", time.time() - start, \"seconds.\\n\")\n",
    "    return winPercent\n",
    "\n",
    "def playTestvsSelf(p1, p2, printturns = False):\n",
    "    start = time.time()\n",
    "    wins = [0, 0]\n",
    "    p1.train = False\n",
    "    p2.train = False\n",
    "    aiWins = 0\n",
    "    winPercent = {}\n",
    "    for i in range(aiTestIterations):\n",
    "        g = game.Game()\n",
    "        g.play(p1, p2, printturns=False)\n",
    "        wins[g.score.index(max(g.score))] += 1\n",
    "        aiWins += 1\n",
    "        winPercent[i] = aiWins / (i + 1)\n",
    "    print(\"Test vs. Self:\\t{} wins to {} wins\".format(wins[0], wins[1]))\n",
    "    print(\"Took \", time.time() - start, \"seconds.\\n\")\n",
    "    return winPercent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "c9fa070b-7636-4cdc-a5a3-01fa3c80171a"
    }
   },
   "outputs": [],
   "source": [
    "def play(p1, p2, printturns = False):\n",
    "    winPercentage1 = playTestvsRandom(p1, p2, printturns)\n",
    "    winPercentage2 = playTrainvsRandom(p1, p2, printturns)\n",
    "\n",
    "    print(\"--------------------------------------------\")\n",
    "\n",
    "    winPercentage3 = playTrainvsSelf(p1, p2, printturns)\n",
    "    winPercentage4 = playTestvsSelf(p1, p2, printturns)\n",
    "    return winPercentage1, winPercentage2, winPercentage3, winPercentage4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "7316d4a6-9634-4f61-b079-9b3a25c7c0bc"
    }
   },
   "source": [
    "## Graphing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "e40e19e4-832a-4046-9890-e1187d0b725a"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def graph_all(board):\n",
    "    graph_board(board)\n",
    "\n",
    "def graph_epsilon():\n",
    "    return 0\n",
    "\n",
    "def graph_board(board):\n",
    "    plt.plot(board.shape[1] - 1, board.shape[1] - 1)\n",
    "    plt.xlim(-1,board.shape[1])\n",
    "    plt.ylim(-1,board.shape[1])\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.axis('off')\n",
    "    plt.gca().axes.get_xaxis().set_visible(False)\n",
    "    plt.gca().axes.get_yaxis().set_visible(False)\n",
    "    \n",
    "    for r in range(board.shape[0]):\n",
    "        for c in range(board.shape[1]):\n",
    "            x = None\n",
    "            if board[r, c] == True:\n",
    "                if r % 2 == 0:\n",
    "                    if c < 5:\n",
    "                        x, y = [c, c + 1], [int(r / 2), int(r / 2)]\n",
    "                else:\n",
    "                    x, y = [c, c], [int(r / 2), int(r / 2) + 1]\n",
    "                if x is not None:\n",
    "                    plt.plot(x, y, color=\"#000000\")\n",
    "    \n",
    "    for i in range(board.shape[1]):\n",
    "        for j in range(board.shape[1]):\n",
    "            plt.scatter(i, j)\n",
    "\n",
    "def graph_win_percentage(winPercent, graphTitle=\"Games Won by Percentage\"):\n",
    "    pointsToPlotPercent = .01\n",
    "    frames = int(len(winPercent) * pointsToPlotPercent)\n",
    "    for key, value in winPercent.items():\n",
    "        if (key % frames == 0):\n",
    "            plt.scatter(key, value, marker='.')\n",
    "    plt.xlim(0, len(winPercent))\n",
    "    plt.ylim(0, 1)\n",
    "    x, y = [0, len(winPercent)], [.5, .5]\n",
    "    plt.plot(x, y, color=\"r\")\n",
    "    xlabel('Games')\n",
    "    ylabel('Win (%)')\n",
    "    title(graphTitle)\n",
    "    print(\"Final Percent Win: \", winPercent[len(winPercent) - 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "118b21cc-eeb9-4c3c-b53e-33b48b5c683d"
    }
   },
   "source": [
    "## Control\n",
    "\n",
    "These parameters will represent our control data. We are playing one Random Player against another Random Player to determine if there is little variance in two palyers chosing random moves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "d70bff23-b3c1-4f1b-968f-283a3eecacc7"
    }
   },
   "outputs": [],
   "source": [
    "trainIterations = 20000\n",
    "randTestIterations = 2000\n",
    "rho = 0.2\n",
    "initialEpsilon = 1.0\n",
    "epsilonDecay = 0.99\n",
    "seed1 = None\n",
    "seed2 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random vs. Random (Control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "aa0ef74e-7908-4611-9c78-30677e93f2ef"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random vs. Random: 987 wins to 1013 wins (2000 games total).\n",
      "Took 5.18863320350647 seconds.\n",
      "Final Percent Win:  0.4935\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAGHCAYAAABrpPKuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqhhOJElSVQwnkiSpKv8fwKXUhDrmfSkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f5cfc06f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random vs. Random\n",
    "chaosIterations = 2000\n",
    "start = time.time()\n",
    "wins = [0, 0]\n",
    "winRecordTracker = {}\n",
    "p1 = players.RandomPlayer()\n",
    "p2 = players.RandomPlayer()\n",
    "\n",
    "for i in range(chaosIterations):\n",
    "    g = game.Game()\n",
    "    g.play(p1, p2)\n",
    "    wins[g.score.index(max(g.score))] += 1\n",
    "    winRecordTracker[i] = wins[0] / (i + 1)\n",
    "\n",
    "print(\"Random vs. Random: {} wins to {} wins ({} games total).\".format(wins[0], wins[1], chaosIterations))\n",
    "print(\"Took\", time.time() - start, \"seconds.\")\n",
    "graph_win_percentage(winRecordTracker, \"Random vs. Random Win Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5e82d6cb-49e5-433d-ac64-39411d847123"
    }
   },
   "source": [
    "#### Observations\n",
    "We can see that win percentages keep roughly around 50%, which was expected when two players simply choosing random moves go against each other.\n",
    "\n",
    "An intersting observation that we saw was when training the data against another Random player, wins started slowly decreasing. After increasing the number of iterations 10-fold, we noticed that that discrimination went away, leading to ~50% win/loss ratio.\n",
    "\n",
    "These are expected and show that there is no significant discrimination between which player goes first and winning the game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5b4de502-4549-4419-bea4-2163e10a2094"
    }
   },
   "source": [
    "## Experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5b6566a5-1a78-42ba-a592-aa385e00aefd"
    }
   },
   "source": [
    "Here is the first instance of testing our AI based on Reinforcement Learning versus our Random Player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "5e59690f-d041-4130-8fbf-7fcb756b705a"
    }
   },
   "outputs": [],
   "source": [
    "trainIterations = 2000\n",
    "randTestIterations = 200\n",
    "aiTrainIterations = 2000\n",
    "aiTestIterations = 200\n",
    "rho = 0.2\n",
    "initialEpsilon = 1.0\n",
    "epsilonDecay = 0.99\n",
    "seed1 = None\n",
    "seed2 = None\n",
    "\n",
    "p1 = players.AIPlayer(rho=rho, epsilon=initialEpsilon, seed=seed1)\n",
    "p2 = players.RandomPlayer(seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "d1ab7798-e556-4c12-b562-e98951195a24"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "winPercent1, winPercent2, winPercent3, winPercent4 = play(p1, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "101dd95c-c122-4328-8c92-1e2eac425018"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph_win_percentage(winPercent1, \"Train vs. Random Wins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "cecbf15b-c43f-4660-aa48-34e40eb714bc"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph_win_percentage(winPercent2, \"Test vs. Random Wins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "22e0ac3f-511a-4fa9-b306-24b53fc2ce31"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph_win_percentage(winPercent3, \"Train vs. Self Wins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "670a1f3d-df47-4222-a214-54056ac848b8"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph_win_percentage(winPercent4, \"Test vs. Self Wins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "16886ab7-3238-4f0b-ae49-02f6c8da43ac"
    }
   },
   "source": [
    "#### Obserations\n",
    "The data clearly shows that using reinforcement versus a random player will result in consistent wins. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ad6b9b50-b4ce-4204-a263-0597424ab1a5"
    }
   },
   "source": [
    "## Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "56c25cb6-977b-49fe-bc19-ab1063c9b5b8"
    }
   },
   "source": [
    "We decided to increase the number of games played between the AI and the Random Player, and the AI against another AI. Iteration counts were multiplied by 10 compared to our control to see how quickly our AI could learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "fe1d6dd9-b406-49a4-b351-b68bcf52a667"
    }
   },
   "outputs": [],
   "source": [
    "trainIterations = 20000\n",
    "randTestIterations = 2000\n",
    "aiTrainIterations = 20000\n",
    "aiTestIterations = 2000\n",
    "rho = 0.2\n",
    "initialEpsilon = 1.0\n",
    "epsilonDecay = 0.99\n",
    "seed1 = None\n",
    "seed2 = None\n",
    "\n",
    "p1 = players.AIPlayer(rho=rho, epsilon=initialEpsilon, seed=seed1)\n",
    "p2 = players.RandomPlayer(seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "cdb945c0-7fa4-4393-a8c5-23ed7d4fe0d7"
    }
   },
   "outputs": [],
   "source": [
    "winPercent1, winPercent2, winPercent3, winPercent4 = play(p1, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "3207df74-c4fe-4992-8e73-7af39e82ef94"
    }
   },
   "outputs": [],
   "source": [
    "graph_win_percentage(winPercent1, \"Train vs. Random Wins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "4dd901f2-6daa-4624-b098-12bd03c9e024"
    }
   },
   "outputs": [],
   "source": [
    "graph_win_percentage(winPercent2, \"Test vs. Random Wins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "c582b548-6ddf-45db-a8cb-0a742e8dc1f2"
    }
   },
   "outputs": [],
   "source": [
    "graph_win_percentage(winPercent3, \"Train vs. Self Wins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "3becfeac-7719-4e97-bfba-6b8d800fac63"
    }
   },
   "outputs": [],
   "source": [
    "graph_win_percentage(winPercent4, \"Test vs. Self Wins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "19d1602e-dc88-44a0-b21b-09b2eaabbdb0"
    }
   },
   "source": [
    "#### Observations\n",
    "We noticed ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e2b31f83-3699-4977-aca0-825b4978536a"
    }
   },
   "source": [
    "# Experiment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "50ea3fb0-ed11-44c4-ada0-80b2b8c18281"
    }
   },
   "source": [
    "We wanted to see what would happen if we put an AI Reinforced player up against another AI Reinforced player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "1d5698dd-f814-4d0d-a7b9-2846d1036ca5"
    }
   },
   "outputs": [],
   "source": [
    "trainIterations = 2000\n",
    "randTestIterations = 200\n",
    "aiTrainIterations = 2000\n",
    "aiTestIterations = 200\n",
    "rho = 0.2\n",
    "initialEpsilon = 1.0\n",
    "epsilonDecay = 0.99\n",
    "seed1 = None\n",
    "seed2 = None\n",
    "\n",
    "p1 = players.AIPlayer(rho=rho, epsilon=initialEpsilon, seed=seed1)\n",
    "p2 = players.AIPlayer(rho=rho, epsilon=initialEpsilon, seed=seed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "8519dc70-ca9d-4605-bd93-887ac0dae7ca"
    }
   },
   "outputs": [],
   "source": [
    "winPercent1, winPercent2, winPercent3, winPercent4 = play(p1, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "5b7e9085-fa51-411a-84b0-d623b341eb3e"
    }
   },
   "outputs": [],
   "source": [
    "graph_win_percentage(winPercent1, \"Train vs. Random Wins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "fe5c9344-1a24-40d0-9696-e83893391c38"
    }
   },
   "outputs": [],
   "source": [
    "graph_win_percentage(winPercent2, \"Test vs. Random Wins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "9108af01-dd4b-4231-b557-821533d27807"
    }
   },
   "outputs": [],
   "source": [
    "graph_win_percentage(winPercent3, \"Train vs. Self Wins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "a820957a-1702-48f1-9069-00d1137db67b"
    }
   },
   "outputs": [],
   "source": [
    "graph_win_percentage(winPercent4, \"Test vs. Self Wins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "fc578005-d344-4cc0-b5c7-f737a08b5cae"
    }
   },
   "source": [
    "#### Observations\n",
    "We noticed..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "fe158f1c-1b7c-403d-83e6-0136bb4c924c"
    }
   },
   "source": [
    "# Experiment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "7137c067-3058-415a-9cd5-af1ced9b92ab"
    }
   },
   "source": [
    "This is what we are doing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "2a7f2cc8-1810-41bc-8f01-501999815177"
    }
   },
   "outputs": [],
   "source": [
    "trainIterations = 2000\n",
    "randTestIterations = 200\n",
    "aiTrainIterations = 2000\n",
    "aiTestIterations = 200\n",
    "rho = 0.2\n",
    "initialEpsilon = 1.0\n",
    "epsilonDecay = 0.99\n",
    "seed1 = None\n",
    "seed2 = None\n",
    "\n",
    "p1 = players.AIPlayer(rho=rho, epsilon=initialEpsilon, seed=seed1)\n",
    "p2 = players.RandomPlayer(seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "84825925-7a6e-438e-b341-1f70bbe62427"
    }
   },
   "outputs": [],
   "source": [
    "winPercent1, winPercent2, winPercent3, winPercent4 = play(p1, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "8078f250-4fb7-462a-8d58-a1932df3799c"
    }
   },
   "outputs": [],
   "source": [
    "graph_win_percentage(winPercent1, \"Train vs. Random Wins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "29da0bc7-4738-462d-9c28-ef877d1b0855"
    }
   },
   "outputs": [],
   "source": [
    "graph_win_percentage(winPercent2, \"Test vs. Random Wins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "f80248c3-0256-48bf-a05b-cf7757acfef0"
    }
   },
   "outputs": [],
   "source": [
    "graph_win_percentage(winPercent3, \"Train vs. Self Wins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "652b385a-440c-466f-bbd0-9e70c23f30cf"
    }
   },
   "outputs": [],
   "source": [
    "graph_win_percentage(winPercent4, \"Test vs. Self Wins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "114b9721-f1db-464b-bf28-c835ec56cbe9"
    }
   },
   "source": [
    "#### Ovservations\n",
    "We noticed..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "52888a01-8c87-42fb-ac5f-6401eb9379f8"
    }
   },
   "source": [
    "# For Making Diagrams (REMOVE BEFORE SUBMISSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "15aefb39-a9a3-4a32-8327-f4c561c1dfd1"
    }
   },
   "outputs": [],
   "source": [
    "b = game.Game.Board()\n",
    "\n",
    "b[0, 0] = True\n",
    "\n",
    "b[1, 0] = True\n",
    "b[1, 1] = True\n",
    "\n",
    "b[2, 0] = True\n",
    "\n",
    "b[3, 0] = True\n",
    "b[3, 1] = True\n",
    "\n",
    "b[4, 0] = True\n",
    "\n",
    "b[5, 0] = True\n",
    "b[5, 1] = True\n",
    "\n",
    "b[6, 0] = True\n",
    "b[6, 1] = True\n",
    "b[6, 2] = True\n",
    "\n",
    "b[7, 0] = True\n",
    "b[7, 1] = True\n",
    "b[7, 2] = True\n",
    "b[7, 3] = True\n",
    "\n",
    "b[8, 0] = True\n",
    "b[8, 1] = True\n",
    "b[8, 2] = True\n",
    "\n",
    "b[9, 0] = True\n",
    "b[9, 1] = True\n",
    "b[9, 2] = True\n",
    "b[9, 3] = True\n",
    "\n",
    "b[10, 0] = True\n",
    "b[10, 1] = True\n",
    "b[10, 2] = True\n",
    "\n",
    "graph_board(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "887347f3-66bc-4adf-aaa2-37d8226190b5"
    }
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "869dc1df-5150-4766-8b48-d8776e830853"
    }
   },
   "source": [
    "The data shows ..."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbpresent": {
   "slides": {},
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
