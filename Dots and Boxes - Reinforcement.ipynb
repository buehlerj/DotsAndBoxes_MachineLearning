{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\xv}{\\mathbf{x}}\n",
    "\\newcommand{\\Xv}{\\mathbf{X}}\n",
    "\\newcommand{\\yv}{\\mathbf{y}}\n",
    "\\newcommand{\\zv}{\\mathbf{z}}\n",
    "\\newcommand{\\av}{\\mathbf{a}}\n",
    "\\newcommand{\\Wv}{\\mathbf{W}}\n",
    "\\newcommand{\\wv}{\\mathbf{w}}\n",
    "\\newcommand{\\tv}{\\mathbf{t}}\n",
    "\\newcommand{\\Tv}{\\mathbf{T}}\n",
    "\\newcommand{\\muv}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\sigmav}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\phiv}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\Phiv}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\Sigmav}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\Lambdav}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\half}{\\frac{1}{2}}\n",
    "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\newcommand{\\argmin}[1]{\\underset{#1}{\\operatorname{argmin}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dots and Boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeffrey Buehler<br>\n",
    "Bobby Signor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup\n",
    "    Dots and Boxes is a simple game for two players. The gameboard consists of x dots across by y dots up and down.\n",
    "\n",
    "    ex: An empty 5 x 5 board will look like this\n",
    "                            *   *   *   *   *\n",
    "                                 \n",
    "                            *   *   *   *   *\n",
    "                                 \n",
    "                            *   *   *   *   *\n",
    "                                 \n",
    "                            *   *   *   *   *\n",
    "                                 \n",
    "                            *   *   *   *   *\n",
    "\n",
    "#### Rules\n",
    "    Each player switch off taking turns. A turn consists of drawing a line between two unoccupied side-by-side dots. If the new line the player\n",
    "    draws does not complete a 1 x 1 square, then that player's turn is over and it is the other player's turn.\n",
    "\n",
    "    ex:\n",
    "                *   *   *   *   *              *   *   *   *   *\n",
    "                                                                \n",
    "                *   *---*   *   *              *   *---*   *   *\n",
    "                    |                              |            \n",
    "                *   *   *   *   *     ->       *   *---*   *   *\n",
    "                                                                \n",
    "                *   *   *   *   *              *   *   *   *   *\n",
    "                                                                \n",
    "                *   *   *   *   *              *   *   *   *   *\n",
    "                \n",
    "                        Results in next player's turn\n",
    "\n",
    "\n",
    "    If the player draws a line that completes a 1 x 1 square, the player is rewarded that box and the player takes their turn again.\n",
    "    \n",
    "    ex:\n",
    "                *   *   *   *   *              *   *   *   *   *\n",
    "                                                                \n",
    "                *   *---*   *   *              *   *---*   *   *\n",
    "                    |                              | x |        \n",
    "                *   *---*   *   *     ->       *   *---*   *   *\n",
    "                                                                \n",
    "                *   *   *   *   *              *   *   *   *   *\n",
    "                                                                \n",
    "                *   *   *   *   *              *   *   *   *   *\n",
    "                      Results in owning the box and\n",
    "                            a repeated turn\n",
    "\n",
    "    The game ends when it is no longer possible to draw another line.\n",
    "    ex:\n",
    "        \n",
    "                            *---*---*---*---*\n",
    "                            | x | x | o | x |\n",
    "                            *---*---*---*---*\n",
    "                            | x | x | x | o |\n",
    "                            *---*---*---*---*\n",
    "                            | o | o | o | x |\n",
    "                            *---*---*---*---*\n",
    "                            | x | o | x | x |\n",
    "                            *---*---*---*---*\n",
    "                               where x: 10\n",
    "                                     y: 6\n",
    "\n",
    "    The winner is determined by whoever has the most boxes at the end of\n",
    "    the game. In our example, player x would be the winner.\n",
    "\n",
    "\n",
    "#### Strategy\n",
    "The objective of the game is to score as many boxes as possible, however it is not always wise to complete boxes as quick as possible. One strategy that is quickly learned by human opponents is creating paths that can be completed in succession (fig. 1). Creating and fillint out paths will maximize point output by giving you more opportunities to draw lines and fill boxes. This must be done with discression however, since your opponent may also complete your path, giving them all of the potential points.\n",
    "\n",
    "    fig. 1\n",
    "                *   *   *   *   *              * - *   *   *   *\n",
    "                |   |                          |   |            \n",
    "                *   *   *   *   *              * - *   *   *   *\n",
    "                |   |                          |   |            \n",
    "                *   *---*---*   *     ->       * - *---*---*   *\n",
    "                |   |       |                  |   |   '   |    \n",
    "                *   *   *   *   *              * - * - * - *   *\n",
    "                |       |   |                  |   -   |   |    \n",
    "                *---*---*---*   *              *---*---*---*   *\n",
    "                         This results in a +8 score\n",
    "                               all in one turn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Game\n",
    "The Game object stores information relevant to the game board and environment. Board has all spaces available to play on stored as a numpy array of tuples. Each player's score is kept track of inside of game as well.\n",
    "\n",
    "#### Players\n",
    "There are two types of players that can be created.\n",
    " 1. Random Player: This player chooses moves simply by looking at all of the available moves on the board and choosing one at random. It does not learn, nor improve as each game goes by.\n",
    " 2. AI Player: This player uses Reinforcement Learning (see below) to learn from past games and moves which next possible move would result in a higher percentage win. It will start the first few games by choosing random moves, like the Random Player, but will start choosing higher probability moves at an exponential rate as games go on and it learns better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Machine Learning Method: Reinforcement Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reinforcement Learning\n",
    "Reinforcement learning is a method of machine learning used to teach a program to give correct output given input using reward/punishment. The behavior of a reinforced program is based on the psychological response of humans trying to suceed at a task. One way to picture this is to imagine a child being taught how to read by a grade-school teacher. They are presented with simple words and are asked to sound out the word. If presented incorrectly, the teacher will inform the child they were wrong and give feedback on how to improve. If the child pronounces the word correctly, they are given positive feedback, and sometimes some sort of reward. Eventually, the child will learn that certain letters interact with others in certian ways because they were given positive reinforcement when they did something correct.\n",
    "\n",
    "#### Applied to AI Player\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Game\n",
    "The Game object contains...\n",
    "\n",
    "##### Players\n",
    "The Players object contains..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import game\n",
    "import players\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def play(p1, p2):\n",
    "    aiWins = 0\n",
    "    for i in range(trainIterations):\n",
    "        g = game.Game()\n",
    "        if i % 2 is 0:\n",
    "            g.play(p1, p2, printturns=printturns)\n",
    "        else:\n",
    "            g.play(p2, p1, printturns=printturns)\n",
    "        if g.score.index(max(g.score)) is p1.playernum:\n",
    "            aiWins += 1\n",
    "        p1.epsilon *= epsilonDecay\n",
    "    print(\"Train vs. Random:\\t{} wins out of {}\".format(aiWins, trainIterations))\n",
    "\n",
    "    aiWins = 0\n",
    "    p1.train = False\n",
    "    for i in range(randTestIterations):\n",
    "        g = game.Game()\n",
    "        if i % 2 is 0:\n",
    "            g.play(p1, p2, printturns=printturns)\n",
    "        else:\n",
    "            g.play(p2, p1, printturns=printturns)\n",
    "        if g.score.index(max(g.score)) is p1.playernum:\n",
    "            aiWins += 1\n",
    "    print(\"Test vs. Random:\\t{} wins out of {}\".format(aiWins, randTestIterations))\n",
    "\n",
    "    print(\"--------------------------------------------\")\n",
    "\n",
    "    wins = [0, 0]\n",
    "    p1.train = True\n",
    "    p1.epsilon = initialEpsilon\n",
    "    p2 = players.AIPlayer(rho=rho, epsilon=initialEpsilon, seed=seed2)\n",
    "    p2.Q = p1.Q\n",
    "    for i in range(aiTrainIterations):\n",
    "        g = game.Game()\n",
    "        g.play(p1, p2, printturns=False)\n",
    "        wins[g.score.index(max(g.score))] += 1\n",
    "        p1.epsilon *= epsilonDecay\n",
    "        p2.epsilon *= epsilonDecay\n",
    "    print(\"Train vs. Self:\\t{} wins to {} wins\".format(wins[0], wins[1]))\n",
    "\n",
    "    wins = [0, 0]\n",
    "    p1.train = False\n",
    "    p2.train = False\n",
    "    for i in range(aiTestIterations):\n",
    "        g = game.Game()\n",
    "        g.play(p1, p2, printturns=False)\n",
    "        wins[g.score.index(max(g.score))] += 1\n",
    "    print(\"Test vs. Self:\\t{} wins to {} wins\".format(wins[0], wins[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graph_all:\n",
    "    return 0\n",
    "\n",
    "def graph_epsilon:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rho = rho = 0.2\n",
    "initialEpsilon = 1.0\n",
    "epsilonDecay = 0.99\n",
    "seed1 = None\n",
    "seed2 = None\n",
    "\n",
    "printturns = False\n",
    "\n",
    "trainIterations = 2000\n",
    "randTestIterations = 200\n",
    "aiTrainIterations = 2000\n",
    "aiTestIterations = 200\n",
    "rho = 0.2\n",
    "initialEpsilon = 1.0\n",
    "epsilonDecay = 0.99\n",
    "seed1 = None\n",
    "seed2 = None\n",
    "\n",
    "trainIterations = 2000\n",
    "randTestIterations = 200\n",
    "aiTrainIterations = 2000\n",
    "aiTestIterations = 200\n",
    "\n",
    "p1 = players.AIPlayer(rho=rho, epsilon=initialEpsilon, seed=seed1)\n",
    "p2 = players.RandomPlayer(seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train vs. Random:\t1997 wins out of 2000\n",
      "Test vs. Random:\t200 wins out of 200\n",
      "--------------------------------------------\n",
      "Train vs. Self:\t192 wins to 1808 wins\n",
      "Test vs. Self:\t0 wins to 200 wins\n"
     ]
    }
   ],
   "source": [
    "play(p1, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8637566029922327e-09\n"
     ]
    }
   ],
   "source": [
    "print(p1.epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation 4"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
